# ğŸ“ app/services/s3_service.py
# AWS S3 íŒŒì¼ ì—…ë¡œë“œ ì„œë¹„ìŠ¤ (IRSA ì‚¬ìš©) + Redis ìºì‹±

import boto3
from botocore.config import Config
import uuid
import json
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
from botocore.exceptions import ClientError, NoCredentialsError
from app.core.config import settings
import logging
import redis

logger = logging.getLogger(__name__)

# Redis í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
redis_client = None
if settings.REDIS_URL:
    try:
        redis_client = redis.from_url(
            f"redis://{settings.REDIS_URL}",
            decode_responses=True,
            socket_timeout=5,
            socket_connect_timeout=5
        )
        redis_client.ping()
        logger.info(f"âœ… Redis ì—°ê²° ì„±ê³µ: {settings.REDIS_URL}")
    except Exception as e:
        logger.warning(f"âš ï¸ Redis ì—°ê²° ì‹¤íŒ¨, ìºì‹± ë¹„í™œì„±í™”: {e}")
        redis_client = None


class S3Service:
    """
    AWS S3 íŒŒì¼ ì—…ë¡œë“œ ì„œë¹„ìŠ¤
    - IRSA (IAM Role for Service Account) ì‚¬ìš©
    - Presigned URL ìƒì„±
    - íŒŒì¼ ì—…ë¡œë“œ/ë‹¤ìš´ë¡œë“œ
    """
    
    def __init__(self):
        """S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (IRSA ì‚¬ìš©)"""
        try:
            # IRSA ì‚¬ìš© - Access Key ì—†ì´ IAM Roleë¡œ ì¸ì¦
            # signature_version='s3v4' í•„ìˆ˜: IRSA Presigned URL ì„œëª… ê²€ì¦ì„ ìœ„í•´ í•„ìš”
            self.region = settings.S3_REGION
            self.s3_client = boto3.client(
                "s3",
                region_name=self.region,
                endpoint_url=f"https://s3.{self.region}.amazonaws.com",
                config=Config(
                    signature_version='s3v4',
                    s3={"addressing_style": "virtual"}
                ),
            )
            self.bucket_name = settings.S3_BUCKET_NAME
            logger.info(f"âœ… S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ë²„í‚·: {self.bucket_name}, ë¦¬ì „: {self.region}, signature: s3v4)")
        except NoCredentialsError:
            logger.warning("âš ï¸ AWS ìê²© ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ - ê°œë°œ ëª¨ë“œë¡œ ì‹¤í–‰")
            self.s3_client = None
            self.bucket_name = settings.S3_BUCKET_NAME
        except Exception as e:
            logger.error(f"âŒ S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.s3_client = None
            self.bucket_name = settings.S3_BUCKET_NAME

    def generate_s3_key(self, filename: str, user_id: str) -> str:
        """
        S3 í‚¤ ìƒì„± (íŒŒì¼ ê²½ë¡œ)
        
        í˜•ì‹: {user_id}/library/{ë…„ë„}/{ì›”}/{uuid}.{í™•ì¥ì}
        ì˜ˆì‹œ: 14780408-6031-704d-19af-ab1893f6b8e5/library/2026/01/550e8400-e29b-41d4.jpg
        """
        now = datetime.utcnow()
        file_extension = filename.split('.')[-1] if '.' in filename else ''
        unique_filename = f"{uuid.uuid4()}.{file_extension}" if file_extension else str(uuid.uuid4())
        
        s3_key = f"{user_id}/library/{now.year}/{now.month:02d}/{unique_filename}"
        return s3_key

    def generate_thumbnail_key(self, s3_key: str) -> str:
        """
        ì¸ë„¤ì¼ S3 í‚¤ ìƒì„±
        
        í˜•ì‹: {user_id}/library/{ë…„ë„}/{ì›”}/thumbs/{uuid}_thumb.{í™•ì¥ì}
        ì˜ˆì‹œ: 14780408-6031-704d-19af-ab1893f6b8e5/library/2026/01/thumbs/550e8400_thumb.jpg
        """
        path_parts = s3_key.rsplit('/', 1)
        if len(path_parts) == 2:
            folder, filename = path_parts
        else:
            folder, filename = '', path_parts[0]
        
        name, ext = filename.rsplit('.', 1) if '.' in filename else (filename, '')
        thumbnail_filename = f"{name}_thumb.{ext}" if ext else f"{name}_thumb"
        
        return f"{folder}/thumbs/{thumbnail_filename}"

    async def generate_presigned_upload_url(
        self,
        filename: str,
        content_type: str,
        user_id: str,
        expires_in: int = 3600
    ) -> Dict[str, Any]:
        """
        íŒŒì¼ ì—…ë¡œë“œìš© Presigned URL ìƒì„±
        
        Args:
            filename: ì—…ë¡œë“œí•  íŒŒì¼ëª…
            content_type: íŒŒì¼ MIME íƒ€ì…
            user_id: ì‚¬ìš©ì ID
            expires_in: URL ë§Œë£Œ ì‹œê°„ (ì´ˆ)
            
        Returns:
            ì—…ë¡œë“œ URL ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        try:
            s3_key = self.generate_s3_key(filename, user_id)
            
            if not self.s3_client:
                # ê°œë°œ í™˜ê²½ì—ì„œ ë”ë¯¸ URL ë°˜í™˜
                return {
                    "upload_url": f"https://{self.bucket_name}.s3.amazonaws.com/{s3_key}?mock=true",
                    "s3_key": s3_key,
                    "expires_in": expires_in,
                    "fields": {},
                    "is_mock": True
                }
            
            # Presigned POST URL ìƒì„± (ë” ì•ˆì „í•¨)
            response = self.s3_client.generate_presigned_post(
                Bucket=self.bucket_name,
                Key=s3_key,
                Fields={
                    "Content-Type": content_type,
                    "x-amz-meta-user-id": user_id,
                    "x-amz-meta-original-filename": filename
                },
                Conditions=[
                    {"Content-Type": content_type},
                    {"x-amz-meta-user-id": user_id},
                    {"x-amz-meta-original-filename": filename},
                    ["content-length-range", 1, 500 * 1024 * 1024]  # 1B ~ 500MB
                ],
                ExpiresIn=expires_in
            )
            
            logger.info(f"Presigned URL ìƒì„±: {filename} -> {s3_key}")
            
            return {
                "upload_url": response["url"],
                "s3_key": s3_key,
                "expires_in": expires_in,
                "fields": response["fields"],
                "is_mock": False
            }
            
        except ClientError as e:
            logger.error(f"S3 Presigned URL ìƒì„± ì‹¤íŒ¨: {e}")
            raise Exception(f"ì—…ë¡œë“œ URL ìƒì„± ì‹¤íŒ¨: {str(e)}")
        except Exception as e:
            logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            raise Exception(f"ì—…ë¡œë“œ URL ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

    async def generate_presigned_download_url(
        self,
        s3_key: str,
        expires_in: int = 3600
    ) -> str:
        """
        íŒŒì¼ ë‹¤ìš´ë¡œë“œìš© Presigned URL ìƒì„± (Redis ìºì‹± ì ìš©)
        
        Args:
            s3_key: S3 íŒŒì¼ í‚¤
            expires_in: URL ë§Œë£Œ ì‹œê°„ (ì´ˆ)
            
        Returns:
            ë‹¤ìš´ë¡œë“œ URL
        """
        try:
            if not self.s3_client:
                # ê°œë°œ í™˜ê²½ì—ì„œ ë”ë¯¸ URL ë°˜í™˜
                return f"https://{self.bucket_name}.s3.amazonaws.com/{s3_key}?mock=true"
            
            # Redis ìºì‹œ í™•ì¸
            cache_key = f"presigned:{s3_key}"
            if redis_client:
                try:
                    cached_url = redis_client.get(cache_key)
                    if cached_url:
                        logger.debug(f"ìºì‹œ íˆíŠ¸: {s3_key}")
                        return cached_url
                except Exception as e:
                    logger.warning(f"Redis ì¡°íšŒ ì‹¤íŒ¨: {e}")
            
            # Presigned URL ìƒì„± (IRSA ì„¸ì…˜ í† í° ìë™ í¬í•¨)
            url = self.s3_client.generate_presigned_url(
                'get_object',
                Params={
                    'Bucket': self.bucket_name,
                    'Key': s3_key,
                    'ResponseCacheControl': 'max-age=3600'
                },
                ExpiresIn=expires_in,
                HttpMethod='GET'
            )
            
            # Redisì— ìºì‹œ ì €ì¥ (TTL: 50ë¶„)
            if redis_client:
                try:
                    redis_client.setex(cache_key, settings.REDIS_TTL, url)
                    logger.debug(f"ìºì‹œ ì €ì¥: {s3_key}")
                except Exception as e:
                    logger.warning(f"Redis ì €ì¥ ì‹¤íŒ¨: {e}")
            
            return url
            
        except ClientError as e:
            logger.error(f"S3 ë‹¤ìš´ë¡œë“œ URL ìƒì„± ì‹¤íŒ¨: {e}")
            raise Exception(f"ë‹¤ìš´ë¡œë“œ URL ìƒì„± ì‹¤íŒ¨: {str(e)}")

    def generate_presigned_url_sync(self, s3_key: str, expires_in: int = 3600) -> str:
        """
        íŒŒì¼ ë‹¤ìš´ë¡œë“œìš© Presigned URL ìƒì„± (ë™ê¸° ë²„ì „, Redis ìºì‹± ì ìš©)
        - ëª¨ë¸ propertyì—ì„œ ì‚¬ìš©
        """
        try:
            if not self.s3_client:
                return f"https://{self.bucket_name}.s3.amazonaws.com/{s3_key}?mock=true"
            
            # Redis ìºì‹œ í™•ì¸
            cache_key = f"presigned:{s3_key}"
            if redis_client:
                try:
                    cached_url = redis_client.get(cache_key)
                    if cached_url:
                        logger.debug(f"ìºì‹œ íˆíŠ¸ (sync): {s3_key}")
                        return cached_url
                except Exception as e:
                    logger.warning(f"Redis ì¡°íšŒ ì‹¤íŒ¨: {e}")
            
            url = self.s3_client.generate_presigned_url(
                'get_object',
                Params={
                    'Bucket': self.bucket_name,
                    'Key': s3_key,
                    'ResponseCacheControl': 'max-age=3600'
                },
                ExpiresIn=expires_in,
                HttpMethod='GET'
            )
            
            # Redisì— ìºì‹œ ì €ì¥ (TTL: 50ë¶„)
            if redis_client:
                try:
                    redis_client.setex(cache_key, settings.REDIS_TTL, url)
                    logger.debug(f"ìºì‹œ ì €ì¥ (sync): {s3_key}")
                except Exception as e:
                    logger.warning(f"Redis ì €ì¥ ì‹¤íŒ¨: {e}")
            
            return url
        except ClientError as e:
            logger.error(f"S3 Presigned URL ìƒì„± ì‹¤íŒ¨: {e}")
            from app.core.config import settings
            return f"{settings.BACKEND_BASE_URL}/library/library-items/file/{s3_key}"

    async def delete_file(self, s3_key: str) -> bool:
        """
        S3ì—ì„œ íŒŒì¼ ì‚­ì œ
        
        Args:
            s3_key: ì‚­ì œí•  íŒŒì¼ì˜ S3 í‚¤
            
        Returns:
            ì‚­ì œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            if not self.s3_client:
                logger.info(f"ê°œë°œ ëª¨ë“œ: íŒŒì¼ ì‚­ì œ ì‹œë®¬ë ˆì´ì…˜ - {s3_key}")
                return True
            
            self.s3_client.delete_object(Bucket=self.bucket_name, Key=s3_key)
            logger.info(f"S3 íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {s3_key}")
            return True
            
        except ClientError as e:
            logger.error(f"S3 íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False

    async def copy_file(self, source_key: str, dest_key: str) -> bool:
        """
        S3 ë‚´ì—ì„œ íŒŒì¼ ë³µì‚¬
        
        Args:
            source_key: ì›ë³¸ íŒŒì¼ í‚¤
            dest_key: ëŒ€ìƒ íŒŒì¼ í‚¤
            
        Returns:
            ë³µì‚¬ ì„±ê³µ ì—¬ë¶€
        """
        try:
            if not self.s3_client:
                logger.info(f"ê°œë°œ ëª¨ë“œ: íŒŒì¼ ë³µì‚¬ ì‹œë®¬ë ˆì´ì…˜ - {source_key} -> {dest_key}")
                return True
            
            copy_source = {'Bucket': self.bucket_name, 'Key': source_key}
            self.s3_client.copy_object(
                CopySource=copy_source,
                Bucket=self.bucket_name,
                Key=dest_key
            )
            
            logger.info(f"S3 íŒŒì¼ ë³µì‚¬ ì™„ë£Œ: {source_key} -> {dest_key}")
            return True
            
        except ClientError as e:
            logger.error(f"S3 íŒŒì¼ ë³µì‚¬ ì‹¤íŒ¨: {e}")
            return False

    def get_file_info(self, s3_key: str) -> Optional[Dict[str, Any]]:
        """
        S3 íŒŒì¼ ì •ë³´ ì¡°íšŒ
        
        Args:
            s3_key: íŒŒì¼ S3 í‚¤
            
        Returns:
            íŒŒì¼ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
        """
        try:
            if not self.s3_client:
                # ê°œë°œ í™˜ê²½ì—ì„œ ë”ë¯¸ ì •ë³´ ë°˜í™˜
                return {
                    "size": 1024000,
                    "last_modified": datetime.utcnow(),
                    "content_type": "application/octet-stream",
                    "is_mock": True
                }
            
            response = self.s3_client.head_object(Bucket=self.bucket_name, Key=s3_key)
            
            return {
                "size": response.get("ContentLength", 0),
                "last_modified": response.get("LastModified"),
                "content_type": response.get("ContentType", "application/octet-stream"),
                "metadata": response.get("Metadata", {}),
                "is_mock": False
            }
            
        except ClientError as e:
            logger.error(f"S3 íŒŒì¼ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    def file_exists(self, s3_key: str) -> bool:
        """
        S3 íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        
        Args:
            s3_key: íŒŒì¼ S3 í‚¤
            
        Returns:
            íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ (True/False)
        """
        try:
            if not self.s3_client:
                # ê°œë°œ í™˜ê²½ì—ì„œëŠ” í•­ìƒ ì¡´ì¬í•œë‹¤ê³  ê°€ì •
                return True
            
            self.s3_client.head_object(Bucket=self.bucket_name, Key=s3_key)
            return True
            
        except ClientError as e:
            error_code = e.response.get('Error', {}).get('Code', '')
            if error_code == '404' or error_code == 'NoSuchKey':
                logger.info(f"S3 íŒŒì¼ ì—†ìŒ: {s3_key}")
                return False
            logger.error(f"S3 íŒŒì¼ ì¡´ì¬ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False

    def is_image_file(self, content_type: str) -> bool:
        """ì´ë¯¸ì§€ íŒŒì¼ ì—¬ë¶€ í™•ì¸"""
        return content_type.startswith('image/')

    def is_video_file(self, content_type: str) -> bool:
        """ë¹„ë””ì˜¤ íŒŒì¼ ì—¬ë¶€ í™•ì¸"""
        return content_type.startswith('video/')

    async def upload_file_content(
        self,
        s3_key: str,
        file_content: bytes,
        content_type: str,
        metadata: Optional[Dict[str, str]] = None
    ) -> bool:
        """
        íŒŒì¼ ë‚´ìš©ì„ S3ì— ì§ì ‘ ì—…ë¡œë“œ
        
        Args:
            s3_key: S3 íŒŒì¼ í‚¤
            file_content: ì—…ë¡œë“œí•  íŒŒì¼ ë‚´ìš© (bytes)
            content_type: íŒŒì¼ MIME íƒ€ì…
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°
            
        Returns:
            ì—…ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            if not self.s3_client:
                logger.info(f"ê°œë°œ ëª¨ë“œ: S3 ì—…ë¡œë“œ ì‹œë®¬ë ˆì´ì…˜ - {s3_key}")
                return True
            
            # S3ì— íŒŒì¼ ì—…ë¡œë“œ
            put_object_kwargs = {
                'Bucket': self.bucket_name,
                'Key': s3_key,
                'Body': file_content,
                'ContentType': content_type
            }
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
            if metadata:
                put_object_kwargs['Metadata'] = metadata
            
            self.s3_client.put_object(**put_object_kwargs)
            logger.info(f"S3 íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ: {s3_key} ({len(file_content)} bytes)")
            return True
            
        except ClientError as e:
            logger.error(f"S3 íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
        except Exception as e:
            logger.error(f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return False

    def needs_thumbnail(self, content_type: str) -> bool:
        """ì¸ë„¤ì¼ ìƒì„±ì´ í•„ìš”í•œ íŒŒì¼ íƒ€ì…ì¸ì§€ í™•ì¸"""
        return self.is_image_file(content_type) or self.is_video_file(content_type)

    async def trigger_video_preview_generation(
        self,
        s3_key: str,
        item_id: str
    ) -> Optional[str]:
        """
        ë™ì˜ìƒ í”„ë¦¬ë·° ìƒì„±ì„ ìœ„í•œ Step Functions ì‹¤í–‰
        
        Args:
            s3_key: ì›ë³¸ ë™ì˜ìƒ S3 í‚¤
            item_id: ë¼ì´ë¸ŒëŸ¬ë¦¬ ì•„ì´í…œ ID (DB ì—…ë°ì´íŠ¸ìš©)
            
        Returns:
            Step Functions ì‹¤í–‰ ARN ë˜ëŠ” None
        """
        try:
            # Step Functions í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            sfn_client = boto3.client(
                'stepfunctions',
                region_name=self.region
            )
            
            # Step Functions State Machine ARN
            state_machine_arn = settings.VIDEO_PREVIEW_STATE_MACHINE_ARN
            
            if not state_machine_arn:
                logger.warning("VIDEO_PREVIEW_STATE_MACHINE_ARNì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                return None
            
            # Step Functions ì…ë ¥ ë°ì´í„°
            input_data = {
                "bucket": self.bucket_name,
                "key": s3_key,
                "item_id": item_id
            }
            
            # Step Functions ì‹¤í–‰
            response = sfn_client.start_execution(
                stateMachineArn=state_machine_arn,
                input=json.dumps(input_data)
            )
            
            execution_arn = response.get('executionArn')
            logger.info(f"Step Functions ì‹¤í–‰ ì‹œì‘: {execution_arn}")
            
            return execution_arn
            
        except ClientError as e:
            logger.error(f"Step Functions ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return None
        except Exception as e:
            logger.error(f"í”„ë¦¬ë·° ìƒì„± íŠ¸ë¦¬ê±° ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    def generate_preview_key(self, s3_key: str) -> str:
        """
        í”„ë¦¬ë·° ì˜ìƒ S3 í‚¤ ìƒì„±
        
        í˜•ì‹: previews/{ì›ë³¸íŒŒì¼ëª…}_preview.mp4
        """
        # ì›ë³¸ íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°
        filename = s3_key.split('/')[-1]
        name = filename.rsplit('.', 1)[0] if '.' in filename else filename
        
        return f"previews/{name}_preview.mp4"


# ì „ì—­ S3 ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
s3_service = S3Service()
